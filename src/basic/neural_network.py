#!/usr/bin/env python3
"""
ç®€å•ç¥ç»ç½‘ç»œç¤ºä¾‹
æ¼”ç¤ºGPUåŠ é€Ÿçš„æ·±åº¦å­¦ä¹ è®­ç»ƒ
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import platform
import time
from torch.utils.data import DataLoader, TensorDataset

# è®¾ç½®ä¸­æ–‡å­—ä½“
def setup_chinese_font():
    """è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ"""
    system = platform.system()
    
    if system == "Windows":
        # Windowsç³»ç»Ÿå­—ä½“
        font_list = ['SimHei', 'Microsoft YaHei', 'SimSun', 'KaiTi']
    elif system == "Darwin":  # macOS
        font_list = ['PingFang SC', 'Hiragino Sans GB', 'STHeiti']
    else:  # Linux
        font_list = ['WenQuanYi Micro Hei', 'Noto Sans CJK SC', 'DejaVu Sans']
    
    # å°è¯•è®¾ç½®å­—ä½“
    font_found = False
    for font_name in font_list:
        try:
            plt.rcParams['font.sans-serif'] = [font_name]
            plt.rcParams['axes.unicode_minus'] = False
            # æµ‹è¯•å­—ä½“æ˜¯å¦å¯ç”¨
            test_fig, test_ax = plt.subplots()
            test_ax.text(0.5, 0.5, 'æµ‹è¯•', fontsize=12)
            plt.close(test_fig)
            font_found = True
            print(f"âœ“ æˆåŠŸè®¾ç½®ä¸­æ–‡å­—ä½“: {font_name}")
            break
        except:
            continue
    
    if not font_found:
        print("âš  æœªæ‰¾åˆ°åˆé€‚çš„ä¸­æ–‡å­—ä½“ï¼Œå›¾è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½æ— æ³•æ­£ç¡®æ˜¾ç¤º")
        # ä½¿ç”¨é»˜è®¤å­—ä½“ï¼Œä½†ç¦ç”¨ä¸­æ–‡
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False

# åˆå§‹åŒ–ä¸­æ–‡å­—ä½“
setup_chinese_font()

class SimpleNN(nn.Module):
    """ç®€å•ç¥ç»ç½‘ç»œæ¨¡å‹"""
    
    def __init__(self, input_size=784, hidden_size=512, output_size=10):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)
        self.fc3 = nn.Linear(hidden_size // 2, output_size)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.2)
        
    def forward(self, x):
        x = x.view(x.size(0), -1)  # å±•å¹³è¾“å…¥
        x = self.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.relu(self.fc2(x))
        x = self.dropout(x)
        x = self.fc3(x)
        return x

class CNN(nn.Module):
    """å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹"""
    
    def __init__(self, num_classes=10):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        
        self.pool = nn.MaxPool2d(2, 2)
        self.dropout = nn.Dropout(0.25)
        
        self.fc1 = nn.Linear(128 * 3 * 3, 512)
        self.fc2 = nn.Linear(512, num_classes)
        self.relu = nn.ReLU()
        
    def forward(self, x):
        # å·ç§¯å±‚
        x = self.pool(self.relu(self.conv1(x)))  # 28x28 -> 14x14
        x = self.pool(self.relu(self.conv2(x)))  # 14x14 -> 7x7
        x = self.pool(self.relu(self.conv3(x)))  # 7x7 -> 3x3
        
        x = x.view(x.size(0), -1)  # å±•å¹³
        x = self.dropout(x)
        x = self.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x

def generate_synthetic_data(num_samples=10000, input_size=784, num_classes=10):
    """ç”Ÿæˆåˆæˆæ•°æ®"""
    print(f"ç”Ÿæˆ {num_samples} ä¸ªæ ·æœ¬...")
    
    # ç”Ÿæˆéšæœºç‰¹å¾
    X = torch.randn(num_samples, input_size)
    
    # ç”Ÿæˆæ ‡ç­¾ï¼ˆåŸºäºç‰¹å¾çš„çº¿æ€§ç»„åˆï¼‰
    weights = torch.randn(input_size, num_classes)
    logits = torch.mm(X, weights)
    y = torch.argmax(logits, dim=1)
    
    # åˆ†å‰²è®­ç»ƒå’Œæµ‹è¯•é›†
    train_size = int(0.8 * num_samples)
    X_train, X_test = X[:train_size], X[train_size:]
    y_train, y_test = y[:train_size], y[train_size:]
    
    return X_train, X_test, y_train, y_test

def generate_image_data(num_samples=10000, image_size=28, num_classes=10):
    """ç”Ÿæˆå›¾åƒæ•°æ®"""
    print(f"ç”Ÿæˆ {num_samples} ä¸ªå›¾åƒæ ·æœ¬...")
    
    # ç”Ÿæˆéšæœºå›¾åƒæ•°æ®
    X = torch.randn(num_samples, 1, image_size, image_size)
    
    # ç”Ÿæˆæ ‡ç­¾
    y = torch.randint(0, num_classes, (num_samples,))
    
    # åˆ†å‰²è®­ç»ƒå’Œæµ‹è¯•é›†
    train_size = int(0.8 * num_samples)
    X_train, X_test = X[:train_size], X[train_size:]
    y_train, y_test = y[:train_size], y[train_size:]
    
    return X_train, X_test, y_train, y_test

def train_model(model, train_loader, test_loader, device, epochs=10, lr=0.001):
    """è®­ç»ƒæ¨¡å‹"""
    print(f"å¼€å§‹è®­ç»ƒï¼Œè®¾å¤‡: {device}")
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)
    
    # è®°å½•è®­ç»ƒè¿‡ç¨‹
    train_losses = []
    test_accuracies = []
    
    # è®­ç»ƒå¾ªç¯
    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        start_time = time.time()
        
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(device), target.to(device)
            
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
            
            running_loss += loss.item()
            
            if batch_idx % 100 == 0:
                print(f'Epoch {epoch+1}/{epochs}, Batch {batch_idx}/{len(train_loader)}, '
                      f'Loss: {loss.item():.4f}')
        
        # è®¡ç®—å¹³å‡æŸå¤±
        avg_loss = running_loss / len(train_loader)
        train_losses.append(avg_loss)
        
        # è¯„ä¼°æ¨¡å‹
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(device), target.to(device)
                output = model(data)
                _, predicted = torch.max(output.data, 1)
                total += target.size(0)
                correct += (predicted == target).sum().item()
        
        accuracy = 100 * correct / total
        test_accuracies.append(accuracy)
        
        epoch_time = time.time() - start_time
        print(f'Epoch {epoch+1}/{epochs} å®Œæˆ, '
              f'å¹³å‡æŸå¤±: {avg_loss:.4f}, '
              f'æµ‹è¯•å‡†ç¡®ç‡: {accuracy:.2f}%, '
              f'æ—¶é—´: {epoch_time:.2f}ç§’')
        
        scheduler.step()
    
    return train_losses, test_accuracies

def benchmark_training_speed():
    """è®­ç»ƒé€Ÿåº¦åŸºå‡†æµ‹è¯• - é‡æ–°è®¾è®¡ä»¥çªå‡ºGPUä¼˜åŠ¿"""
    print("=== è®­ç»ƒé€Ÿåº¦åŸºå‡†æµ‹è¯• ===")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # ç”Ÿæˆæ›´å¤§è§„æ¨¡çš„æ•°æ®
    print("ç”Ÿæˆå¤§è§„æ¨¡è®­ç»ƒæ•°æ®...")
    X_train, X_test, y_train, y_test = generate_synthetic_data(50000)  # å¢åŠ åˆ°5ä¸‡æ ·æœ¬
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ - ä½¿ç”¨æ›´å¤§çš„æ‰¹æ¬¡å¤§å°
    train_dataset = TensorDataset(X_train, y_train)
    test_dataset = TensorDataset(X_test, y_test)
    
    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)  # å¢å¤§æ‰¹æ¬¡
    test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)
    
    # æµ‹è¯•ä¸åŒè®¾å¤‡
    devices = ['cpu']
    if torch.cuda.is_available():
        devices.append('cuda')
    
    results = {}
    
    for dev in devices:
        print(f"\nåœ¨ {dev} ä¸Šè®­ç»ƒ...")
        device = torch.device(dev)
        
        # åˆ›å»ºæ›´å¤æ‚çš„æ¨¡å‹
        class LargeNN(nn.Module):
            def __init__(self, input_size=784, hidden_size=2048, output_size=10):
                super(LargeNN, self).__init__()
                self.fc1 = nn.Linear(input_size, hidden_size)
                self.fc2 = nn.Linear(hidden_size, hidden_size)
                self.fc3 = nn.Linear(hidden_size, hidden_size // 2)
                self.fc4 = nn.Linear(hidden_size // 2, hidden_size // 4)
                self.fc5 = nn.Linear(hidden_size // 4, output_size)
                self.relu = nn.ReLU()
                self.dropout = nn.Dropout(0.3)
                
            def forward(self, x):
                x = x.view(x.size(0), -1)
                x = self.dropout(self.relu(self.fc1(x)))
                x = self.dropout(self.relu(self.fc2(x)))
                x = self.dropout(self.relu(self.fc3(x)))
                x = self.dropout(self.relu(self.fc4(x)))
                x = self.fc5(x)
                return x
        
        # åˆ›å»ºå¤§å‹æ¨¡å‹
        model = LargeNN().to(device)
        print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        
        # è®­ç»ƒå¹¶è®¡æ—¶ - å¢åŠ è®­ç»ƒè½®æ•°
        start_time = time.time()
        train_losses, test_accuracies = train_model(
            model, train_loader, test_loader, device, epochs=15  # å¢åŠ è®­ç»ƒè½®æ•°
        )
        total_time = time.time() - start_time
        
        results[dev] = {
            'time': total_time,
            'final_accuracy': test_accuracies[-1],
            'train_losses': train_losses,
            'test_accuracies': test_accuracies,
            'model_params': sum(p.numel() for p in model.parameters())
        }
        
        print(f"{dev} è®­ç»ƒå®Œæˆï¼Œæ€»æ—¶é—´: {total_time:.2f}ç§’")
    
    # æ˜¾ç¤ºç»“æœ
    if len(results) > 1:
        cpu_time = results['cpu']['time']
        gpu_time = results['cuda']['time']
        speedup = cpu_time / gpu_time
        print(f"\nğŸš€ GPUåŠ é€Ÿæ¯”: {speedup:.2f}x")
        print(f"CPUè®­ç»ƒæ—¶é—´: {cpu_time:.2f}ç§’")
        print(f"GPUè®­ç»ƒæ—¶é—´: {gpu_time:.2f}ç§’")
    
    return results

def visualize_training(results):
    """å¯è§†åŒ–è®­ç»ƒç»“æœ - é‡æ–°è®¾è®¡ä»¥çªå‡ºGPUä¼˜åŠ¿"""
    # é‡æ–°è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œç¡®ä¿åœ¨ç»˜å›¾æ—¶ç”Ÿæ•ˆ
    setup_chinese_font()
    
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. è®­ç»ƒæŸå¤±æ›²çº¿
    ax1 = axes[0, 0]
    colors = {'cpu': 'red', 'cuda': 'blue'}
    for device, result in results.items():
        ax1.plot(result['train_losses'], label=f'{device.upper()} è®­ç»ƒæŸå¤±', 
                color=colors.get(device, 'gray'), linewidth=2)
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.set_title('è®­ç»ƒæŸå¤±å¯¹æ¯”', fontsize=14, fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. æµ‹è¯•å‡†ç¡®ç‡æ›²çº¿
    ax2 = axes[0, 1]
    for device, result in results.items():
        ax2.plot(result['test_accuracies'], label=f'{device.upper()} æµ‹è¯•å‡†ç¡®ç‡', 
                color=colors.get(device, 'gray'), linewidth=2)
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy (%)')
    ax2.set_title('æµ‹è¯•å‡†ç¡®ç‡å¯¹æ¯”', fontsize=14, fontweight='bold')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. è®­ç»ƒæ—¶é—´å¯¹æ¯”ï¼ˆçªå‡ºGPUä¼˜åŠ¿ï¼‰
    ax3 = axes[1, 0]
    devices = list(results.keys())
    times = [results[dev]['time'] for dev in devices]
    
    # ä½¿ç”¨ä¸åŒé¢œè‰²çªå‡ºGPUä¼˜åŠ¿
    bar_colors = ['red' if dev == 'cpu' else 'green' for dev in devices]
    bars = ax3.bar(devices, times, color=bar_colors, alpha=0.7, edgecolor='black', linewidth=1)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, time_val in zip(bars, times):
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height + max(times)*0.01,
                f'{time_val:.1f}s', ha='center', va='bottom', fontweight='bold')
    
    ax3.set_xlabel('è®¾å¤‡')
    ax3.set_ylabel('è®­ç»ƒæ—¶é—´ (ç§’)')
    ax3.set_title('è®­ç»ƒæ—¶é—´å¯¹æ¯”', fontsize=14, fontweight='bold')
    ax3.grid(True, alpha=0.3, axis='y')
    
    # 4. åŠ é€Ÿæ¯”å’Œå‡†ç¡®ç‡å¯¹æ¯”
    ax4 = axes[1, 1]
    if len(results) > 1:
        cpu_time = results['cpu']['time']
        gpu_time = results['cuda']['time']
        speedup = cpu_time / gpu_time
        
        # åˆ›å»ºåŒè½´å›¾
        ax4_twin = ax4.twinx()
        
        # å‡†ç¡®ç‡æŸ±çŠ¶å›¾
        accuracies = [results[dev]['final_accuracy'] for dev in devices]
        bars1 = ax4.bar([x-0.2 for x in range(len(devices))], accuracies, 
                       width=0.4, label='æœ€ç»ˆå‡†ç¡®ç‡ (%)', color='lightblue', alpha=0.7)
        
        # åŠ é€Ÿæ¯”æŸ±çŠ¶å›¾ï¼ˆåªåœ¨GPUä¸Šæ˜¾ç¤ºï¼‰
        if 'cuda' in results:
            bars2 = ax4.bar([x+0.2 for x in range(len(devices))], [0, speedup], 
                           width=0.4, label='GPUåŠ é€Ÿæ¯”', color='orange', alpha=0.7)
        
        ax4.set_xlabel('è®¾å¤‡')
        ax4.set_ylabel('å‡†ç¡®ç‡ (%)', color='blue')
        ax4_twin.set_ylabel('åŠ é€Ÿæ¯”', color='orange')
        ax4.set_title(f'æ€§èƒ½å¯¹æ¯” (GPUåŠ é€Ÿæ¯”: {speedup:.1f}x)', fontsize=14, fontweight='bold')
        ax4.set_xticks(range(len(devices)))
        ax4.set_xticklabels(devices)
        ax4.grid(True, alpha=0.3, axis='y')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, acc in zip(bars1, accuracies):
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height + 1,
                    f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('training_benchmark.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # æ‰“å°è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "="*60)
    print("è¯¦ç»†æ€§èƒ½ç»Ÿè®¡")
    print("="*60)
    for device, result in results.items():
        print(f"{device.upper()} è®¾å¤‡:")
        print(f"  è®­ç»ƒæ—¶é—´: {result['time']:.2f} ç§’")
        print(f"  æœ€ç»ˆå‡†ç¡®ç‡: {result['final_accuracy']:.2f}%")
        print(f"  æ¨¡å‹å‚æ•°: {result['model_params']:,}")
    
    if len(results) > 1:
        cpu_time = results['cpu']['time']
        gpu_time = results['cuda']['time']
        speedup = cpu_time / gpu_time
        print(f"\nğŸš€ GPUæ€§èƒ½æå‡:")
        print(f"  åŠ é€Ÿæ¯”: {speedup:.2f}x")
        print(f"  æ—¶é—´èŠ‚çœ: {cpu_time - gpu_time:.2f} ç§’")
        print(f"  æ•ˆç‡æå‡: {(speedup-1)*100:.1f}%")

def main():
    """ä¸»å‡½æ•°"""
    print("PyTorch ç¥ç»ç½‘ç»œç¤ºä¾‹")
    print("=" * 50)
    
    # æ£€æŸ¥è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    print()
    
    # 1. ç®€å•ç¥ç»ç½‘ç»œè®­ç»ƒ
    print("=== ç®€å•ç¥ç»ç½‘ç»œè®­ç»ƒ ===")
    X_train, X_test, y_train, y_test = generate_synthetic_data(5000)
    
    train_dataset = TensorDataset(X_train, y_train)
    test_dataset = TensorDataset(X_test, y_test)
    
    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)
    
    model = SimpleNN().to(device)
    train_losses, test_accuracies = train_model(model, train_loader, test_loader, device)
    
    print(f"æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {test_accuracies[-1]:.2f}%")
    print()
    
    # 2. CNNè®­ç»ƒ
    print("=== CNNè®­ç»ƒ ===")
    X_train, X_test, y_train, y_test = generate_image_data(3000)
    
    train_dataset = TensorDataset(X_train, y_train)
    test_dataset = TensorDataset(X_test, y_test)
    
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
    
    cnn_model = CNN().to(device)
    cnn_train_losses, cnn_test_accuracies = train_model(
        cnn_model, train_loader, test_loader, device, epochs=8
    )
    
    print(f"CNNæœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {cnn_test_accuracies[-1]:.2f}%")
    print()
    
    # 3. æ€§èƒ½åŸºå‡†æµ‹è¯•
    results = benchmark_training_speed()
    
    # 4. å¯è§†åŒ–ç»“æœ
    visualize_training(results)
    
    print("=" * 50)
    print("ç¥ç»ç½‘ç»œç¤ºä¾‹å®Œæˆï¼")

if __name__ == "__main__":
    main() 